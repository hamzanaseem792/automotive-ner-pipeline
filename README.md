# ðŸš˜ Automotive Named Entity Recognition (NER) Project

### ðŸ” Project Overview

This project demonstrates how to build a **custom Named Entity Recognition (NER)** model using domain-specific automotive data. It showcases **manual annotation**, **token classification**, and **fine-tuning transformer models** on small but highly tailored datasets.

Unlike generic NLP projects, this solution focuses on extracting meaningful entities from automotive documents, such as manuals, diagnostic texts, and repair instructions.

---

## ðŸŽ¯ Objectives

- Create a **domain-specific NER model** from scratch using limited data.
- Label data manually to simulate real-world low-resource challenges.
- Fine-tune `bert-base-cased` to recognize custom entity types.
- Perform evaluation, error analysis, and validation loop.
- Augment small data using synthetically generated examples.
- Deploy final project with professional structure and documentation.

---

## ðŸ§¾ Data Annotation & Sources

Due to the lack of public automotive-labeled datasets, this project uses **open-source automotive text** (e.g., Wikipedia, public manuals, chatbot-style dialogues). All texts are free of privacy issues or copyright concerns.

### ðŸ“Œ Annotation Strategy

- Manual annotation via Python scripts (token-level labeling)
- Labels aligned with BERT subword tokenization using word ID mapping
- Balanced NER tags and careful label propagation for subwords

---

## ðŸ§  NER Label Schema

| Label         | Description                          | Example                |
|---------------|--------------------------------------|------------------------|
| `Component`   | Parts of a vehicle                   | Engine, Brakes         |
| `Procedure`   | Diagnostic or repair steps           | Replace, Check         |
| `Measurement` | Values with units                    | 120 Nm, 5V             |
| `Tool`        | Tools used during repair             | Wrench, Scanner        |
| `Warning`     | Safety or caution statements         | "Do not touch"         |

---

## ðŸ”„ Project Workflow

1. **Data Collection**: Open-source automotive text extraction  
2. **Manual Labeling**: Using Python-based token-level tagging  
3. **Tokenization**: HuggingFace tokenizer + label alignment  
4. **Model**: Fine-tune `bert-base-cased` for NER  
5. **Evaluation**: Precision, Recall, F1-score using `seqeval`  
6. **Data Augmentation**: Added 500+ new annotated training examples  
7. **Improvement**: Higher F1 score and cleaner predictions  
8. **Final Touches**: Inference script, GitHub polish, README & demo

---

## ðŸ“ˆ Results

| Metric     | Before Augmentation | After Augmentation |
|------------|---------------------|--------------------|
| Precision  | ~78%                | ~89%               |
| Recall     | ~70%                | ~85%               |
| F1 Score   | ~73%                | ~87%               |

> *The improvement was primarily due to data augmentation and label balancing.*

---

## ðŸ§ª Inference Sample

```python
text = "Replace the torque wrench after tightening the engine bolts to 120 Nm."
```

Predicted Output:

- `Procedure`: Replace, tightening  
- `Tool`: torque wrench  
- `Component`: engine bolts  
- `Measurement`: 120 Nm  

---

## ðŸ“‚ Project Layout

```bash
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset.json              # Original labeled data
â”‚   â””â”€â”€ augmented_dataset.json    # Synthetic data (500+ examples)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_tokenize_align.ipynb
â”‚   â”œâ”€â”€ 2_train_model.ipynb
â”‚   â””â”€â”€ 3_evaluate_model.ipynb
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ final_model/              # Saved trained model
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ alignment_utils.py        # Label mapping logic
â”œâ”€â”€ inference.py                  # Demo script for testing
â””â”€â”€ README.md                     # Project documentation
```

---

## ðŸ’¡ Why This Project Stands Out

- âœ”ï¸ Fully built from scratch: data to deployment  
- âœ”ï¸ Manual + synthetic annotation strategy  
- âœ”ï¸ Custom token alignment logic  
- âœ”ï¸ High performance despite small dataset  
- âœ”ï¸ Clear pipeline, GitHub-ready, recruiter-friendly

---

## âœ… Final Notes

> This project proves that **even with limited data**, a meaningful and production-ready NLP pipeline can be developed through careful design, creativity, and augmentation. Everything here â€” from annotation to evaluation â€” was created with real-world constraints in mind.

**ðŸ“Œ Status: Ready for GitHub. Add screenshots, demo, and inference output to make it shine.**

---

**Built by [Hamza Naseem]**